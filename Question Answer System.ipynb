{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87aa2f-3d2f-4c93-8eb0-f016c4a123aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain-ollama\n",
    "%pip install -U langchain\n",
    "%pip install -U langchain-community\n",
    "\n",
    "##from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6db055-fddd-4872-a4f9-c61ab3b27658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "loader=CSVLoader(file_path='codebasics_faqs.csv', source_column='prompt')\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40808282-a7fc-4f77-9f24-5a347f553b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286532b-10c8-41f8-b147-faa98e4f75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers==2.2.2\n",
    "%pip install InstructorEmbedding\n",
    "%pip install langchain-huggingface\n",
    "%pip install numpy==1.26.4\n",
    "%pip install faiss-cpu\n",
    "##from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# model_name = \"sentence-transformers/quora-distilbert-base\"\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.1\",\n",
    ")\n",
    "#instructor_embedding=HuggingFaceInstructEmbeddings(model_name=model_name)\n",
    "vectordb=FAISS.from_documents(documents=data, embedding=embeddings)\n",
    "print(vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e79655-346e-4662-aa9f-fa6c586d194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectordb.as_retriever()\n",
    "retriever\n",
    "rdocs=retriever.get_relevant_documents(\"what about placement support\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69ce70-643c-43eb-90be-b83f892da832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template=\"\"\"Given the following context and a question, generate an answer based on this content.\n",
    "In the answer try to provide as much text as posssible from \"response\" section in the source document.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT:{context}\n",
    "\n",
    "QUESTION:{question}\"\"\"\n",
    "\n",
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\",\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370f9e3-b61b-43d5-a807-dbaca3285337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3788734-9e70-4c9f-a778-43d6bac025ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain(\"Do you provide internship and EMI Payments\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
